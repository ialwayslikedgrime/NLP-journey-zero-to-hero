{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Semantics: The Foundation of Natural Language Processing\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook explores the theoretical foundations of lexical semantics, which is crucial for text mining and natural language processing. It's fascinating to observe how NLP is deeply rooted in linguistics! Let's explore these fundamental concepts that drive modern text analysis techniques.\n",
    "\n",
    "## Core Concepts in Lexical Semantics\n",
    "\n",
    "### What is Lexical Semantics?\n",
    "\n",
    "**Lexical semantics** is the branch of linguistics that studies the meaning of words. It forms the theoretical basis for many NLP applications including search engines, recommendation systems, sentiment analysis, and machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries we'll use throughout this notebook\n",
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmas and Word Senses\n",
    "\n",
    "A **lemma** (or citation form) is the canonical form of a word. For example:\n",
    "- \"mouse\" is the lemma for both \"mouse\" and \"mice\"\n",
    "- \"sing\" is the lemma for \"sing\", \"sang\", \"sung\"\n",
    "- \"dormir\" (to sleep) in Spanish is the lemma for \"duermes\" (you sleep)\n",
    "\n",
    "Many lemmas have multiple meanings, which leads to the concept of **polysemy**.\n",
    "\n",
    "**Example:** The lemma \"mouse\" can refer to:\n",
    "1. A small rodent\n",
    "2. A hand-operated device that controls a computer cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: The, Lemma: the\n",
      "Word: mice, Lemma: mouse\n",
      "Word: were, Lemma: be\n",
      "Word: running, Lemma: run\n",
      "Word: around, Lemma: around\n",
      "Word: while, Lemma: while\n",
      "Word: I, Lemma: I\n",
      "Word: clicked, Lemma: click\n",
      "Word: my, Lemma: my\n",
      "Word: mouse, Lemma: mouse\n",
      "Word: to, Lemma: to\n",
      "Word: browse, Lemma: browse\n",
      "Word: websites, Lemma: website\n",
      "Word: ., Lemma: .\n"
     ]
    }
   ],
   "source": [
    "# Example: Finding lemmas using spaCy\n",
    "text = \"The mice were running around while I clicked my mouse to browse websites.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Word: {token.text}, Lemma: {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word sense disambiguation** is the computational task of determining which sense of a word is being used in a particular context. This is crucial for accurate machine translation, information retrieval, and content analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTER_DEVICE\n",
      "ANIMAL\n"
     ]
    }
   ],
   "source": [
    "# Simple rule-based word sense disambiguation for \"mouse\"\n",
    "def simple_mouse_disambiguation(sentence):\n",
    "    computer_terms = [\"click\", \"cursor\", \"computer\", \"screen\", \"keyboard\"]\n",
    "    animal_terms = [\"cat\", \"rodent\", \"trap\", \"cheese\", \"pet\"]\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Count context clues\n",
    "    computer_score = sum(1 for term in computer_terms if term in sentence)\n",
    "    animal_score = sum(1 for term in animal_terms if term in sentence)\n",
    "    \n",
    "    if computer_score > animal_score:\n",
    "        return \"COMPUTER_DEVICE\"\n",
    "    elif animal_score > computer_score:\n",
    "        return \"ANIMAL\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "# Test cases\n",
    "print(simple_mouse_disambiguation(\"I need a new mouse because my cursor keeps freezing\"))\n",
    "print(simple_mouse_disambiguation(\"The cat chased the mouse around the kitchen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Relationships\n",
    "\n",
    "#### Synonymy\n",
    "\n",
    "**Synonymy** refers to words with identical or very similar meanings. Perfect synonyms would be completely interchangeable without changing the truth conditions of a sentence.\n",
    "\n",
    "Examples of synonym pairs:\n",
    "- couch/sofa\n",
    "- car/automobile \n",
    "- vomit/throw up\n",
    "- filbert/hazelnut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using WordNet to find synonyms\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return set(synonyms)  # Remove duplicates\n",
    "\n",
    "print(\"Synonyms of 'car':\", get_synonyms(\"car\"))\n",
    "print(\"Synonyms of 'happy':\", get_synonyms(\"happy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Principle of Contrast** (Girard 1718, Bréal 1897, Clark 1987) argues that no two words are exactly synonymous - differences in form always signal some difference in meaning. For example, while \"water\" and \"H₂O\" refer to the same substance, they differ in usage contexts. \"H₂O\" is appropriate in scientific contexts, while \"water\" is more suitable in everyday situations.\n",
    "\n",
    "#### Word Similarity vs. Relatedness\n",
    "\n",
    "**Word similarity** measures how alike two words are in meaning. For example, \"cat\" and \"dog\" are quite similar as they're both common household pets, even though they're different animals.\n",
    "\n",
    "**Word relatedness** captures a broader relationship between words that may not be similar but commonly appear in the same contexts. For example, \"coffee\" and \"cup\" aren't similar (one is a beverage, the other is a container), but they're strongly related through usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "Similarity between 'cat' and 'dog': 0.87980753\n",
      "Similarity between 'coffee' and 'cup': 0.33575124\n",
      "Words most similar to 'doctor':\n",
      "  physician: 0.7673\n",
      "  nurse: 0.7522\n",
      "  dr.: 0.7175\n",
      "  doctors: 0.7081\n",
      "  patient: 0.7074\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating word similarity vs. relatedness using word vectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained word vectors\n",
    "word_vectors = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "# Similarity between similar words\n",
    "print(\"Similarity between 'cat' and 'dog':\", \n",
    "      word_vectors.similarity('cat', 'dog'))\n",
    "\n",
    "# Similarity between related but not similar words\n",
    "print(\"Similarity between 'coffee' and 'cup':\", \n",
    "      word_vectors.similarity('coffee', 'cup'))\n",
    "\n",
    "# Finding most similar words\n",
    "print(\"Words most similar to 'doctor':\")\n",
    "for word, score in word_vectors.most_similar('doctor', topn=5):\n",
    "    print(f\"  {word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Fields and Topic Models\n",
    "\n",
    "A **semantic field** is a set of words related to a common domain or concept. Words in the same semantic field are often related by context rather than synonymy.\n",
    "\n",
    "Examples of semantic fields:\n",
    "- Hospital field: surgeon, scalpel, nurse, anesthetic, hospital\n",
    "- Restaurant field: waiter, menu, plate, food, chef\n",
    "- House field: door, roof, kitchen, family, bed\n",
    "\n",
    "**Topic models** like Latent Dirichlet Allocation (LDA) use unsupervised learning to discover these semantic fields automatically from text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.080*\"using\" + 0.080*\"doctor\" + 0.080*\"hospital\" + 0.080*\"surgery\" + 0.080*\"scalpel\" + 0.080*\"performed\" + 0.020*\"house\" + 0.020*\"waiter\" + 0.020*\"menus\" + 0.020*\"restaurant\"\n",
      "Topic 1: 0.062*\"house\" + 0.061*\"room\" + 0.061*\"their\" + 0.061*\"living\" + 0.061*\"relaxed\" + 0.061*\"family\" + 0.061*\"delicious\" + 0.061*\"chef\" + 0.061*\"meal\" + 0.061*\"kitchen\"\n",
      "Topic 2: 0.050*\"roof\" + 0.050*\"storm\" + 0.050*\"repairs\" + 0.050*\"needed\" + 0.050*\"after\" + 0.050*\"nurse\" + 0.050*\"medication\" + 0.050*\"ward\" + 0.050*\"table\" + 0.050*\"patients\"\n"
     ]
    }
   ],
   "source": [
    "# Simple topic modeling with LDA\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Sample documents representing different topics\n",
    "documents = [\n",
    "    \"The doctor performed surgery using a scalpel in the hospital\",\n",
    "    \"The nurse administered medication to patients in the ward\",\n",
    "    \"The waiter brought menus to the table at the restaurant\",\n",
    "    \"The chef prepared a delicious meal in the kitchen\",\n",
    "    \"The family relaxed in the living room of their house\",\n",
    "    \"The roof of the house needed repairs after the storm\"\n",
    "]\n",
    "\n",
    "# Preprocess documents\n",
    "processed_docs = [[word.lower() for word in doc.split() if len(word) > 3] \n",
    "                 for doc in documents]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = Dictionary(processed_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=3,\n",
    "    passes=10\n",
    ")\n",
    "\n",
    "# Display topics\n",
    "for topic_id, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {topic_id}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Frames and Roles\n",
    "\n",
    "A **semantic frame** represents a set of words that denote perspectives or participants in a particular type of event. Different words can describe the same event from different perspectives.\n",
    "\n",
    "Example: Commercial Transaction Frame\n",
    "- Buyer perspective: \"Sam bought a book from Ling\"\n",
    "- Seller perspective: \"Ling sold a book to Sam\"\n",
    "- Focus on money: \"Sam paid Ling for a book\"\n",
    "\n",
    "Semantic frames contain **semantic roles** (like buyer, seller, goods, money), and words in a sentence fill these roles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'purchase', 'buyer': 'Sam', 'seller': 'Ling', 'goods': 'book'}\n",
      "{'event': 'sale', 'buyer': 'Sam', 'seller': 'Ling', 'goods': 'book'}\n"
     ]
    }
   ],
   "source": [
    "# Simple semantic role analyzer for buying/selling events\n",
    "def analyze_transaction(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    frame = {\"event\": None, \"buyer\": None, \"seller\": None, \"goods\": None}\n",
    "    \n",
    "    # Very simplified analysis\n",
    "    for token in doc:\n",
    "        if token.lemma_ == \"buy\":\n",
    "            frame[\"event\"] = \"purchase\"\n",
    "            # Subject is typically the buyer\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ == \"nsubj\":\n",
    "                    frame[\"buyer\"] = child.text\n",
    "                # Direct object is typically the goods\n",
    "                elif child.dep_ == \"dobj\":\n",
    "                    frame[\"goods\"] = child.text\n",
    "                # \"from\" typically marks the seller\n",
    "                elif child.dep_ == \"prep\" and child.text == \"from\":\n",
    "                    for seller in child.children:\n",
    "                        if seller.dep_ == \"pobj\":\n",
    "                            frame[\"seller\"] = seller.text\n",
    "        \n",
    "        elif token.lemma_ == \"sell\":\n",
    "            frame[\"event\"] = \"sale\"\n",
    "            # Subject is typically the seller\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ == \"nsubj\":\n",
    "                    frame[\"seller\"] = child.text\n",
    "                # Direct object is typically the goods\n",
    "                elif child.dep_ == \"dobj\":\n",
    "                    frame[\"goods\"] = child.text\n",
    "                # \"to\" typically marks the buyer\n",
    "                elif child.dep_ == \"prep\" and child.text == \"to\":\n",
    "                    for buyer in child.children:\n",
    "                        if buyer.dep_ == \"pobj\":\n",
    "                            frame[\"buyer\"] = buyer.text\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Test with different perspectives\n",
    "print(analyze_transaction(\"Sam bought a book from Ling\"))\n",
    "print(analyze_transaction(\"Ling sold a book to Sam\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connotation and Sentiment\n",
    "\n",
    "**Connotation** refers to the emotional or evaluative meaning associated with a word, beyond its literal definition. Words carry positive, negative, or neutral connotations that impact how a message is received.\n",
    "\n",
    "Example contrasts:\n",
    "- Positive vs. Negative: \"curious\" (positive) vs. \"nosy\" (negative)  \n",
    "- Formal vs. Informal: \"residence\" (formal) vs. \"pad\" (informal)\n",
    "- Technical vs. Everyday: \"H₂O\" (technical) vs. \"water\" (everyday)\n",
    "\n",
    "According to early work by Osgood et al. (1957), words vary along three dimensions:\n",
    "\n",
    "1. **Valence**: the pleasantness of the stimulus (happy → high, sad → low)\n",
    "2. **Arousal**: the intensity of emotion provoked (excited → high, calm → low)\n",
    "3. **Dominance**: the degree of control exerted (controlling → high, influenced → low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis using VADER\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example sentences with different connotations\n",
    "sentences = [\n",
    "    \"The movie was absolutely wonderful and inspiring.\",\n",
    "    \"The film was okay, nothing special.\",\n",
    "    \"That movie was terrible and a complete waste of time.\",\n",
    "    \"The young man was curious about how the machine worked.\",\n",
    "    \"The nosy neighbor kept looking through our windows.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiment\n",
    "for sentence in sentences:\n",
    "    sentiment_scores = sid.polarity_scores(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"  Sentiment: {sentiment_scores}\")\n",
    "    \n",
    "    # Interpret the compound score\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        print(\"  Overall: Positive\")\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        print(\"  Overall: Negative\")\n",
    "    else:\n",
    "        print(\"  Overall: Neutral\")\n",
    "    print()\n",
    "\n",
    "# Visualizing words in the valence-arousal-dominance space\n",
    "vad_words = {\n",
    "    'courageous': [8.05, 5.5, 7.38],  # [valence, arousal, dominance]\n",
    "    'music': [7.67, 5.57, 6.5],\n",
    "    'heartbreak': [2.45, 5.65, 3.58],\n",
    "    'cub': [6.71, 3.95, 4.24],\n",
    "    'happy': [8.2, 6.0, 7.0],\n",
    "    'sad': [2.1, 4.0, 3.0],\n",
    "    'angry': [2.5, 7.5, 6.8]\n",
    "}\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "vad_df = pd.DataFrame.from_dict(vad_words, orient='index', \n",
    "                               columns=['Valence', 'Arousal', 'Dominance'])\n",
    "\n",
    "# Plot in 3D space\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(vad_df['Valence'], vad_df['Arousal'], vad_df['Dominance'], s=50)\n",
    "\n",
    "# Add word labels\n",
    "for word, pos in zip(vad_df.index, vad_df.values):\n",
    "    ax.text(pos[0], pos[1], pos[2], word, size=12)\n",
    "\n",
    "ax.set_xlabel('Valence')\n",
    "ax.set_ylabel('Arousal')\n",
    "ax.set_zlabel('Dominance')\n",
    "ax.set_title('Words in Valence-Arousal-Dominance Space')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "Lexical semantics concepts have numerous practical applications in NLP:\n",
    "\n",
    "1. **Search Engine Optimization**: Understanding synonyms, semantic fields, and word relationships helps search engines return relevant results even when query terms don't exactly match document terms.\n",
    "\n",
    "2. **Chatbots and Virtual Assistants**: Word sense disambiguation and semantic frames enable more natural interactions by correctly interpreting user requests in context.\n",
    "\n",
    "3. **Content Recommendation**: Semantic similarity helps recommend relevant articles, products, or media based on users' interests.\n",
    "\n",
    "4. **Sentiment Analysis**: Applications in market research, social media monitoring, and customer feedback analysis use connotation and sentiment to gauge public opinion.\n",
    "\n",
    "5. **Machine Translation**: Understanding semantic frames and word relationships across languages enables more accurate translations.\n",
    "\n",
    "6. **Text Summarization**: Identifying key semantic fields and important concepts helps in creating concise summaries.\n",
    "\n",
    "7. **Question Answering Systems**: Understanding semantic roles and frames helps systems correctly interpret questions and find appropriate answers.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Lexical semantics provides the theoretical foundation for many modern NLP techniques. By understanding how words relate to each other in meaning, we can build more sophisticated systems for processing and generating human language. As NLP continues to evolve, these fundamental linguistic concepts remain essential for creating truly intelligent language technologies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-journey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
